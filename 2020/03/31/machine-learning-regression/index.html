<!DOCTYPE html><html lang="en" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Regression | Julien Zouein</title><meta name="description" content="In this course, we will speak about regression in machine Learning"><meta name="keywords" content="Machine Learning,Course,Introduction,Regression"><meta name="author" content="Julien Zouein"><meta name="copyright" content="Julien Zouein"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Regression"><meta name="twitter:description" content="In this course, we will speak about regression in machine Learning"><meta name="twitter:image" content="http://yoursite.com/img/cover/ml.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Regression"><meta property="og:url" content="http://yoursite.com/2020/03/31/machine-learning-regression/"><meta property="og:site_name" content="Julien Zouein"><meta property="og:description" content="In this course, we will speak about regression in machine Learning"><meta property="og:image" content="http://yoursite.com/img/cover/ml.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://yoursite.com/2020/03/31/machine-learning-regression/"><link rel="prev" title="Classification" href="http://yoursite.com/2020/04/05/machine-learning-classification/"><link rel="next" title="Machine Learning Introduction" href="http://yoursite.com/2020/03/30/machine-learning-intro/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Julien Zouein</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Post</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/profile.jpg" onerror="onerror=null;src='/img/wallpaper_default.jpg'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">6</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">16</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">10</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Post</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Introduction"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Introduction</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Simple-Linear-Regression"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">Simple Linear Regression</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Find-the-best-parameters"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">Find the best parameters</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Mathematical-method"><span class="toc_mobile_items-number">2.1.1.</span> <span class="toc_mobile_items-text">Mathematical method</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Model-evaluation"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">Model evaluation</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Train-and-test-on-the-same-dataset"><span class="toc_mobile_items-number">2.2.1.</span> <span class="toc_mobile_items-text">Train and test on the same dataset</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Train-and-test-on-splited-datasets"><span class="toc_mobile_items-number">2.2.2.</span> <span class="toc_mobile_items-text">Train and test on splited datasets</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#K-fold-cross-validation"><span class="toc_mobile_items-number">2.2.2.1.</span> <span class="toc_mobile_items-text">K-fold cross validation</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#Evalutation-Metrics"><span class="toc_mobile_items-number">2.2.3.</span> <span class="toc_mobile_items-text">Evalutation Metrics</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Multiple-Linear-Regression"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Multiple Linear Regression</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Optimization-of-Theta"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">Optimization of $\Theta$</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Non-Linear-Regression"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">Non-Linear Regression</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Simple-Linear-Regression"><span class="toc-number">2.</span> <span class="toc-text">Simple Linear Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Find-the-best-parameters"><span class="toc-number">2.1.</span> <span class="toc-text">Find the best parameters</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Mathematical-method"><span class="toc-number">2.1.1.</span> <span class="toc-text">Mathematical method</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-evaluation"><span class="toc-number">2.2.</span> <span class="toc-text">Model evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Train-and-test-on-the-same-dataset"><span class="toc-number">2.2.1.</span> <span class="toc-text">Train and test on the same dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Train-and-test-on-splited-datasets"><span class="toc-number">2.2.2.</span> <span class="toc-text">Train and test on splited datasets</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#K-fold-cross-validation"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">K-fold cross validation</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Evalutation-Metrics"><span class="toc-number">2.2.3.</span> <span class="toc-text">Evalutation Metrics</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multiple-Linear-Regression"><span class="toc-number">3.</span> <span class="toc-text">Multiple Linear Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Optimization-of-Theta"><span class="toc-number">3.1.</span> <span class="toc-text">Optimization of $\Theta$</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Non-Linear-Regression"><span class="toc-number">4.</span> <span class="toc-text">Non-Linear Regression</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(/img/cover/ml.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">Regression</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> Created 2020-03-31<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> Updated 2020-05-04</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Course/">Course</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Course/Machine-Learning/">Machine Learning</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>Post View:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Let us take this dataset. This dataset have several features :</p>
<ul>
<li>Size</li>
<li>#Room</li>
<li>#Floor</li>
</ul>
<p>and seems to have a label : <em>Price</em></p>
<p><a href="https://zupimages.net/up/20/14/ot1n.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="Exemple Dataset" class="fancybox"><img alt="Exemple Dataset" title="Exemple Dataset" data-src="https://zupimages.net/up/20/14/ot1n.png" class="lazyload"></a></p>
<p>To summarize, this dataset gives us the price of several houses with their characteristics.</p>
<p>We are interested in the price of a house who just arrived on the market and which was not estimate by experts yet. Is it possible to have an approximation of this price, given the elements given and the dataset we have ?</p>
<p>We can use regression to predict continuous values such as price using some features as a variable.</p>
<p>We have two types of varaibles : </p>
<ul>
<li>Dependant Variable : in our case the price</li>
<li>Independant Variable : one or many, here it is the size, number of rooms and number of floors.</li>
</ul>
<p>Most of the timen Independant Variable are noted X and the dependant varaible y.</p>
<p>In regression, the dependant variable must be a continuous value. It can  not be a discrete value (boolean, class, …)$\$<br>However, the independant variables can be either, discret or continuous value.</p>
<p>What we want to do in our exemple, is using our historical data to train a model, and then once we will input “a new house” to this model, it will give us the approximative price.</p>
<p>Linear regression is based on the relationship between independant and dependant variables.<br>We have several cases :</p>
<ul>
<li>When we have one independant variable (for exemple the size), it is called a Simple Regression</li>
<li>When we have more then one independant variables (let us add #room and #floor), it is called a Multiple Regression</li>
</ul>
<p>The regression can be linear or non-linear</p>
<blockquote>
<p>Linear Regression : In regression, linear regression is when we try to find a linear relationship, between independant and dependant variables. It means that the variables will increase or dicrease simultaneously keeping the same rate.<br>$$∃ F | ∀ X, F : X ↦AX+B$$</p>
</blockquote>
<blockquote>
<p>Non-Linear : In regression, non linear regression is when we find a non linear relationship, between independant and dependant variables. It means that change in one entity will not correspond to a change in the other entity.$\$<br>For exemple :<br>$$F:X↦X^{2}$$<br>is an non linear equation.</p>
</blockquote>
<h2 id="Simple-Linear-Regression"><a href="#Simple-Linear-Regression" class="headerlink" title="Simple Linear Regression"></a>Simple Linear Regression</h2><p>Simple Linear regression is about predicting a value (dependant variable) using a single other value (single independant variable)$\$<br>For exemple, to predict the price of a house only based on its size.</p>
<p>to easely understand linear regression, is can be useful to represent the dataset on a graph.</p>
<hr>
<p>let’s see the result with our house price prediction dataset</p>
<p><a href="https://zupimages.net/up/20/14/le6u.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="Exemple Dataset" class="fancybox"><img alt="Exemple Dataset" title="Exemple Dataset" data-src="https://zupimages.net/up/20/14/le6u.png" class="lazyload"></a></p>
<p>On this scatter plot we have the price (in k$) considering the available squarefit for living. We can easely see that a line can be drawn, through all the points, following the distribuution of the points. Linear Regression is about finding that line.</p>
<hr>
<p>Linear regression is about finding the relation between independant and dependant variables (relation between X and Y).</p>
<p>The fit line is shown as the followinf equation :<br>$$ \hat{y}=\theta_{0}+\theta_{1} x_{1}$$</p>
<p>it is written as a polynome.</p>
<ul>
<li>$\hat{y}$ represent the predicted variable. It is the value found with the equation. It is different from y, which represent the real value.With the perfect equation, $\hat{y}$=y.</li>
<li>$\theta_{0}$ and $\theta_{1}$ are the parameter we want to find.<ul>
<li>$\theta_{1}$ is none as the slop of the curve</li>
</ul>
</li>
<li>$x_{1}$ is the one of the feature of our dataset (living squarefit for exemple)</li>
</ul>
<p>Now we know the model of a linear regression. We need to learn ho to find the parameters $\theta_{0}$ and $\theta_{1}$ to find the best line to fit our data.</p>
<hr>
<p>If we use the previous graph :</p>
<p><a href="https://zupimages.net/up/20/14/le6u.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="Exemple Dataset" class="fancybox"><img alt="Exemple Dataset" title="Exemple Dataset" data-src="https://zupimages.net/up/20/14/le6u.png" class="lazyload"></a></p>
<p>If we take a house with 4$\times10^{6}$squarefits. The real value of a house with that size seems to be around 700,000$. But if we take the value given by our fit line, we find a price around 900,000$</p>
<p>By comparing the two values, we will be able to find the “error”. In our case we have a 200,000$ error (900000-700000=200000).<br>Taking the mean of all points, shows in our case that our life fit poorly with the data.</p>
<hr>
<p>Being able to compute and understand the error will help us to adapt our parameters in order to have the best fit line.</p>
<p>A common value used is called the Mean Squared Error (MSE) :<br>$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y_{i}})^{2}$$<br>our objective is to find a line where we minimize the MSE. MSE can also be written with $\theta_{0}$ and $\theta_{1}$ :</p>
<p>$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_{i}-(\theta_{0}+\theta_{1}x_{i}))^{2}$$<br>By writting the MSE this way, it clearly appears that the only parameters we can twist to modify our MSE value are $\theta_{0}$ and $\theta_{1}$.</p>
<h3 id="Find-the-best-parameters"><a href="#Find-the-best-parameters" class="headerlink" title="Find the best parameters"></a>Find the best parameters</h3><p>In simple Linear regression, whe have two way to calculate the best parameters. Using Mathematical or optimizing methods.</p>
<h4 id="Mathematical-method"><a href="#Mathematical-method" class="headerlink" title="Mathematical method"></a>Mathematical method</h4><p>The mathematical method requires a lot of calculation, and can be done since we only have one independant variable. We calculate our parameters directly from the data given in our dataset.</p>
<p>Let us imagine that we have a dataset we s entry in it. it can be shown that :</p>
<ul>
<li>$\theta_{1}$=$\frac{\sum_{i=1}^{s}(x_{i} -\bar{x})(y_{i}-\bar{y})}{\sum_{i=1}^{s}(x_{i} -\bar{x})^{2}}$</li>
<li>$\theta_{0}$=$\bar{y}-\theta_{1}\bar{x}$</li>
</ul>
<p>We need the calculate the mean of both the dependant and independant variables.</p>
<p>WThe optimizing method is more useful (more general). But in our case, and with only one independant variable, it can beconsidered as overkill.</p>
<h3 id="Model-evaluation"><a href="#Model-evaluation" class="headerlink" title="Model evaluation"></a>Model evaluation</h3><p>The goal of regression is to build a model to predict unkonwn cases. Once we have built a model, we still need to evaluate it.</p>
<p>a lot of methods can be used, and a lot of metrics.</p>
<h4 id="Train-and-test-on-the-same-dataset"><a href="#Train-and-test-on-the-same-dataset" class="headerlink" title="Train and test on the same dataset"></a>Train and test on the same dataset</h4><p>We have a dataset of house, with the living squarefit and the price for each house.$\$<br>We will then train our model with this dataset. Now, we want to know how it performs. To do so, we select an amout of exemple from our dataset. We split the label (price) from the feature (living squarefit).</p>
<p>We will use this set of exemples to evaluate our dataset. We use our model to predict the price. We will now compare the predicted price with the real value (since our set of exemple come from our dataset).</p>
<p>Training and testing on the same dataset will give us, high training accuracy. Our model will perform perfectly on our dataset. However we do not want our model to perform good on data we already know, but on unknown data. However, Train and test on the same dataset, does not allow us to know the accuracy on unknown data.</p>
<h4 id="Train-and-test-on-splited-datasets"><a href="#Train-and-test-on-splited-datasets" class="headerlink" title="Train and test on splited datasets"></a>Train and test on splited datasets</h4><p>In this appproach, we split our dataset in two parts : </p>
<ul>
<li>training part</li>
<li>testing part</li>
</ul>
<p>A common split is 70% of the dataset for training and 30% if the dataset for testing.</p>
<p>Now that our dataset is splited in two smaller dataset, we will use the training dataset to create our model. Nothing will change execpt that we have a smaller amount of data.</p>
<p>Once our model is trained we can now use the testing dataset to know how our model perform with unknow data.$\$<br>Since we did not trained with testing dataset, when we will predict the values from this dataset and compare them with real values, we will know the accuracy of our model with data it never saw before.</p>
<p>Creating the train set and the test set is a difficult task, since we do not train anymore with all the given data. A bad distribution could lead to a bad model with poor performance.$\$<br>Indeed, by doing the Train and test on splited datasets, our training will be dependent on which datasets the data is trained.</p>
<p>To fix this issue, we use a method called K-fold cross validation.</p>
<h5 id="K-fold-cross-validation"><a href="#K-fold-cross-validation" class="headerlink" title="K-fold cross validation"></a>K-fold cross validation</h5><p>What is k-fold cross validation ?</p>
<p>K-fold cross validation is about training and testing a model on K different Train/test split dataset.</p>
<p>We will then take the mean of what was calculated in order to have a more precise model.</p>
<h4 id="Evalutation-Metrics"><a href="#Evalutation-Metrics" class="headerlink" title="Evalutation Metrics"></a>Evalutation Metrics</h4><p>There is a lot of evaluation Metrics.$\$<br>Metrics are useful because they give us insights on what should be optimize in the model.$\$<br>We have a lot of evaluation metrics and will show you ones of the most used metrics.</p>
<p>They are all based on the error. In the context of regression, error is the difference between a real value and the fit line.</p>
<ul>
<li>MAE : Mean Absolut Error, is easy to understand since it is the mean of the sum of all the errors.<br>$$ \frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y_i}|$$</li>
<li>MSE : Mean Squared Error, is one of the most used evaluation metrics. It is different from the MAE because it gives a highest weight to the large errors<br>$$ \frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y_{i}})^{2}$$</li>
<li>RMSE : Root Mean Squared Error, is also used by data science community. Because it is interpretable in the same units as the response vector. It is basically the square root of MSE<br>$$ \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y_{i}})^{2}}$$</li>
<li>RAE : Relative Absolut Error, It takes the total absolut error and then normalize it.<br>$$\frac{\sum_{i=1}^{n}|y_{i}-\hat{y_i}|}{\sum_{i=1}^{n}|y_{i}-\bar{y}|}$$</li>
<li>Relative Squared Error is similar to RAE, execpt we take the squared error instead of absolute error<br>$$ \frac{\sum_{i=1}^{n}(y_{i}-\hat{y_i})^{2}}{\sum_{i=1}^{n}(y_{i}-\bar{y})^{2}}$$</li>
</ul>
<p>this are some of the most common metrics we can see in Machine Leaning.</p>
<h2 id="Multiple-Linear-Regression"><a href="#Multiple-Linear-Regression" class="headerlink" title="Multiple Linear Regression"></a>Multiple Linear Regression</h2><p>As it is for Simple Linear Regression, Multiple Linear Regression is about finding the relation between dependant and independant variables, execpt that, in Multiple Linear Regression, we will use multiple independant variables.</p>
<p>We will use several features (X) to predict a label (y).</p>
<blockquote>
<p>We use uppercase letters to express matrices and lowercase for vectors.</p>
</blockquote>
<p>Our new equations is now written :<br>$$ \hat{y} = \Theta^{T}\times X$$<br>with :</p>
<ul>
<li>$\Theta=[\theta_{0},\theta_{1},…,\theta_{n}]$</li>
<li>$X=[x_{0},x_{1},x_{2},…,x_{n}]$</li>
<li>$x_{0}$=1</li>
</ul>
<hr>
<p>for a number of feature equal to three, we will have :<br>$$\begin{array}{cll}<br>    \hat{y}&amp;=&amp;\theta_{0}\times x_{0}+ \theta_{1}\times x_{1}+ \theta_{2}\times x_{2}+ \theta_{3}\times x_{3}\<br>    &amp;=&amp;\theta_{0} + \theta_{1}\times x_{1}+ \theta_{2}\times x_{2}+ \theta_{3}\times x_{3}<br>\end{array}$$</p>
<p>for a number of features equals to one, we will have :</p>
<p>$$\begin{array}{cll}<br>    \hat{y}&amp;=&amp;\theta_{0}\times x_{0}+ \theta_{1}\times x_{1}\<br>    &amp;=&amp;\theta_{0} + \theta_{1}\times x_{1}<br>\end{array}$$<br>It is the same equation as the one given in Simple Linear Regression.</p>
<hr>
<p>As for the Simple linear Regression we want to minimize the error, in our case we will take the MSE. To do so we want to optimize the parameters $\Theta$. </p>
<h3 id="Optimization-of-Theta"><a href="#Optimization-of-Theta" class="headerlink" title="Optimization of $\Theta$"></a>Optimization of $\Theta$</h3><p>For the Simple Linear Regression we saw that we could use mathematical approach. However in our case, we can not use this method. We will use optimization approach.</p>
<p>As an optimisation algorithm, we can use gradiant descent. It is a proper approach when you have multiple features and a large dataset.</p>
<p>The equation to calculate the gradient descent is : </p>
<p>$$\theta_{i} := \theta_{i}-\alpha \frac{\delta}{\delta\theta_{i}}MSE(X,\Theta)$$</p>
<p>This equation make us find the best parameters to minimize MSE. It help us find a way to a local minimum</p>
<blockquote>
<p>it is important to notice that a local minimum may not be the general minimum.</p>
</blockquote>
<p>This algorithm should converge to the local minimum of MSE.</p>
<ul>
<li>All the calculation are made simultaneously. All parameters are updated at  the same time</li>
<li>$\alpha$ is called the learning rate, it gives us the “upgrade step” for each iteration of the gradiant descent. A small $\alpha$ will take time to converge, a big $\alpha$ may not converge at all</li>
</ul>
<p>Once we have found our parameters, we are able to predict our label according to those parameters.$\$<br>Based on the parameters, we can also find which independant variables have the most impact on the label.</p>
<h2 id="Non-Linear-Regression"><a href="#Non-Linear-Regression" class="headerlink" title="Non-Linear Regression"></a>Non-Linear Regression</h2><p>We will briefly talk about non-linear regression.$\$<br>In some case, we may face non linear data (for exemple the GDP of a country). This non-linear data cannot be predicted using Linear Regression. Indeed, Linear Regression supposed that your data is linear.</p>
<p>There are some Regression model fiting every situation. Going from Linear Regression to cubic Regression and so on. Those models are called Polynomial Regression.</p>
<p>Polynomial Regression fits a curve line to the data for exemple :<br>$$\hat{y}=\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+…+\theta_{n}x^{n}$$</p>
<p>It is possible to find a linear regression from a polynomial regression. With :<br>$$\begin{array}{lll}<br>    x_{1}&amp;=&amp;x\<br>    x_{2}&amp;=&amp;x^{2}\<br>    &amp;…&amp;\<br>    x_{n}&amp;=&amp;x^{n}<br>\end{array}$$</p>
<p>We easely find our new expression as :<br>$$\hat{y}=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+…+\theta_{n}x_{n}$$<br>which is the formula we saw for linear regression.</p>
<p>A non-linear regression is based on a non-linear equation. There are a lot of possibilities. The function must be a non-linear function of parameters $\theta$ not necessarily the features “$x$”.</p>
<p>In order to know if you have to use a linear or non-linear regression, the easiest way is to plot your data and check visually if it would better fit a linear or non-linear regression. By analyzing the accuracy after a first attempt you may also be able to adapt your choice.</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Julien Zouein</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/03/31/machine-learning-regression/">http://yoursite.com/2020/03/31/machine-learning-regression/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning    </a><a class="post-meta__tags" href="/tags/Course/">Course    </a><a class="post-meta__tags" href="/tags/Introduction/">Introduction    </a><a class="post-meta__tags" href="/tags/Regression/">Regression    </a></div><div class="post_share"><div class="social-share" data-image="/img/cover/ml.jpg" data-sites="facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/05/machine-learning-classification/"><img class="prev_cover lazyload" data-src="/img/cover/ml.jpg" onerror="onerror=null;src='/img/wallpaper_default.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>Classification</span></div></a></div><div class="next-post pull_right"><a href="/2020/03/30/machine-learning-intro/"><img class="next_cover lazyload" data-src="/img/cover/ml.jpg" onerror="onerror=null;src='/img/wallpaper_default.jpg'"><div class="label">Next Post</div><div class="next_info"><span>Machine Learning Introduction</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/05/machine-learning-classification/" title="Classification"><img class="relatedPosts_cover lazyload"data-src="/img/cover/ml.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-05</div><div class="relatedPosts_title">Classification</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/30/machine-learning-intro/" title="Machine Learning Introduction"><img class="relatedPosts_cover lazyload"data-src="/img/cover/ml.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-30</div><div class="relatedPosts_title">Machine Learning Introduction</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Julien Zouein</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><i class="darkmode fa fa-sun-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>